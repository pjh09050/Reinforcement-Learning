{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def state(self, s):\n",
    "    state = 0\n",
    "    for bit in s:\n",
    "        state = state * 2 + bit\n",
    "    if len(s) > 0:\n",
    "        state += 2 ** (len(s) + 1)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_array = [1,1,1,1,1,1]\n",
    "decimal = 0\n",
    "for bit in binary_array:\n",
    "    decimal = decimal * 2 + bit\n",
    "if len(binary_array) > 0:\n",
    "    decimal += 2 ** len(binary_array) - 1\n",
    "decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 회 최적정책 리워드는  999\n",
      "2 회 최적정책 리워드는  999\n",
      "3 회 최적정책 리워드는  999\n",
      "4 회 최적정책 리워드는  999\n",
      "5 회 최적정책 리워드는  999\n",
      "6 회 최적정책 리워드는  6\n",
      "7 회 최적정책 리워드는  999\n",
      "8 회 최적정책 리워드는  999\n",
      "9 회 최적정책 리워드는  999\n",
      "10 회 최적정책 리워드는  999\n",
      "11 회 최적정책 리워드는  999\n",
      "12 회 최적정책 리워드는  999\n",
      "13 회 최적정책 리워드는  999\n",
      "14 회 최적정책 리워드는  6\n",
      "15 회 최적정책 리워드는  999\n",
      "16 회 최적정책 리워드는  999\n",
      "17 회 최적정책 리워드는  999\n",
      "18 회 최적정책 리워드는  6\n",
      "19 회 최적정책 리워드는  999\n",
      "20 회 최적정책 리워드는  999\n",
      "21 회 최적정책 리워드는  999\n",
      "22 회 최적정책 리워드는  999\n",
      "23 회 최적정책 리워드는  999\n",
      "24 회 최적정책 리워드는  999\n",
      "25 회 최적정책 리워드는  999\n",
      "26 회 최적정책 리워드는  999\n",
      "27 회 최적정책 리워드는  999\n",
      "28 회 최적정책 리워드는  999\n",
      "29 회 최적정책 리워드는  999\n",
      "30 회 최적정책 리워드는  6\n",
      "31 회 최적정책 리워드는  999\n",
      "32 회 최적정책 리워드는  999\n",
      "33 회 최적정책 리워드는  999\n",
      "34 회 최적정책 리워드는  999\n",
      "35 회 최적정책 리워드는  999\n",
      "36 회 최적정책 리워드는  999\n",
      "37 회 최적정책 리워드는  999\n",
      "38 회 최적정책 리워드는  999\n",
      "39 회 최적정책 리워드는  999\n",
      "40 회 최적정책 리워드는  999\n",
      "41 회 최적정책 리워드는  999\n",
      "42 회 최적정책 리워드는  999\n",
      "43 회 최적정책 리워드는  999\n",
      "44 회 최적정책 리워드는  999\n",
      "45 회 최적정책 리워드는  999\n",
      "46 회 최적정책 리워드는  999\n",
      "47 회 최적정책 리워드는  999\n",
      "48 회 최적정책 리워드는  999\n",
      "49 회 최적정책 리워드는  999\n",
      "50 회 최적정책 리워드는  999\n",
      "51 회 최적정책 리워드는  999\n",
      "52 회 최적정책 리워드는  999\n",
      "53 회 최적정책 리워드는  999\n",
      "54 회 최적정책 리워드는  999\n",
      "55 회 최적정책 리워드는  999\n",
      "56 회 최적정책 리워드는  6\n",
      "57 회 최적정책 리워드는  6\n",
      "58 회 최적정책 리워드는  999\n",
      "59 회 최적정책 리워드는  999\n",
      "60 회 최적정책 리워드는  999\n",
      "61 회 최적정책 리워드는  999\n",
      "62 회 최적정책 리워드는  999\n",
      "63 회 최적정책 리워드는  999\n",
      "64 회 최적정책 리워드는  999\n",
      "65 회 최적정책 리워드는  999\n",
      "66 회 최적정책 리워드는  999\n",
      "67 회 최적정책 리워드는  999\n",
      "68 회 최적정책 리워드는  999\n",
      "69 회 최적정책 리워드는  999\n",
      "70 회 최적정책 리워드는  999\n",
      "71 회 최적정책 리워드는  999\n",
      "72 회 최적정책 리워드는  999\n",
      "73 회 최적정책 리워드는  999\n",
      "74 회 최적정책 리워드는  999\n",
      "75 회 최적정책 리워드는  999\n",
      "76 회 최적정책 리워드는  999\n",
      "77 회 최적정책 리워드는  6\n",
      "78 회 최적정책 리워드는  999\n",
      "79 회 최적정책 리워드는  999\n",
      "80 회 최적정책 리워드는  999\n",
      "81 회 최적정책 리워드는  6\n",
      "82 회 최적정책 리워드는  999\n",
      "83 회 최적정책 리워드는  999\n",
      "84 회 최적정책 리워드는  999\n",
      "85 회 최적정책 리워드는  999\n",
      "86 회 최적정책 리워드는  999\n",
      "87 회 최적정책 리워드는  999\n",
      "88 회 최적정책 리워드는  6\n",
      "89 회 최적정책 리워드는  999\n",
      "90 회 최적정책 리워드는  999\n",
      "91 회 최적정책 리워드는  999\n",
      "92 회 최적정책 리워드는  999\n",
      "93 회 최적정책 리워드는  999\n",
      "94 회 최적정책 리워드는  999\n",
      "95 회 최적정책 리워드는  999\n",
      "96 회 최적정책 리워드는  999\n",
      "97 회 최적정책 리워드는  999\n",
      "98 회 최적정책 리워드는  999\n",
      "99 회 최적정책 리워드는  999\n",
      "100 회 최적정책 리워드는  999\n",
      "909.63 은 평균\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.s= \"\"\n",
    "        \n",
    "    def step(self, a):\n",
    "        if a==0:\n",
    "            if self.s == \"01010\":\n",
    "                reward = +1000\n",
    "            else:\n",
    "                reward = -1\n",
    "            self.move_left()\n",
    "        elif a==1: \n",
    "            reward = +1    \n",
    "            self.move_right()    \n",
    "        done = self.is_done()\n",
    "        return self.s, reward, done\n",
    "    \n",
    "    def move_left(self):\n",
    "        self.s = self.s+\"0\"\n",
    "        \n",
    "    def move_right(self):\n",
    "        self.s = self.s+\"1\"\n",
    "    \n",
    "    def is_done(self):\n",
    "        if len(self.s) == 6:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.s = \"\"\n",
    "        return self.s\n",
    "    \n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((2048,2))\n",
    "        self.eps = 0.9\n",
    "        self.alpha = 0.1\n",
    "    \n",
    "    def get_fitness(self, s):\n",
    "        fitness = 0\n",
    "        for i in range(len(s)):\n",
    "            if s[-i-1]==\"0\":\n",
    "                fitness = fitness + 2**(i)\n",
    "            else:\n",
    "                fitness = fitness + 2 * 2**(i)\n",
    "        return fitness\n",
    "        \n",
    "    def select_action(self, s):\n",
    "        coin = random.random()\n",
    "        k = self.get_fitness(s)\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,1)\n",
    "        else:\n",
    "            action_val = self.q_table[k,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "    \n",
    "    def select_action2(self, s):\n",
    "        k = self.get_fitness(s)\n",
    "        action_val = self.q_table[k,:]\n",
    "        action = np.argmax(action_val)\n",
    "        return action\n",
    "    \n",
    "    def update_table(self, transition):\n",
    "        s, a, r, s_prime = transition\n",
    "        k = self.get_fitness(s)\n",
    "        next_k = s_prime\n",
    "        a_prime = self.select_action(s_prime) \n",
    "        next_k=self.get_fitness(next_k)\n",
    "        self.q_table[k,a] = self.q_table[k,a] + self.alpha * (r + self.q_table[next_k, a_prime] - self.q_table[k,a])\n",
    "            \n",
    "    def anneal_eps(self):\n",
    "        self.eps -=0.001\n",
    "        self.eps = max(self.eps, 0.2)\n",
    "    \n",
    "    def show(self):\n",
    "        print(self.q_table.tolist())\n",
    "        print(self.eps)\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    env = GridWorld()\n",
    "    agent = QAgent()\n",
    "\n",
    "    for n_epi in range(1000):\n",
    "        done = False\n",
    "        \n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            agent.update_table((s,a,r,s_prime))\n",
    "            s = s_prime\n",
    "        agent.anneal_eps()\n",
    "        # if n_epi%10==0 or n_epi<10:\n",
    "           #print(n_epi,\"에피소드가 지남\")\n",
    "    #agent.show()\n",
    "    \n",
    "    done=False\n",
    "    s=env.reset()\n",
    "    r_sum=0\n",
    "    while not done:\n",
    "        a = agent.select_action2(s)\n",
    "        s_prime, r, done = env.step(a)\n",
    "        r_sum= r_sum+r\n",
    "        s = s_prime\n",
    "    #print(s,r_sum)\n",
    "    #agent.show_table()\n",
    "    return r_sum\n",
    "\n",
    "av=0\n",
    "for i in range(100):\n",
    "    r_sum=main()\n",
    "    print(i+1 , \"회 최적정책 리워드는 \", r_sum)\n",
    "    av=r_sum+av\n",
    "print(av/100,\"은 평균\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 0] 999\n",
      "1 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "2 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "3 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "4 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "5 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "6 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "7 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "8 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "9 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "10 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "11 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "12 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "13 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "14 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "15 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "16 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "17 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "18 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "19 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "20 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "21 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "22 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "23 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "24 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "25 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "26 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "27 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "28 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "29 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "30 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "31 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "32 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "33 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "34 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "35 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "36 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "37 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "38 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "39 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "40 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "41 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "42 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "43 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "44 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "45 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "46 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "47 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "48 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "49 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "50 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "51 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "52 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "53 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "54 회 최적정책 리워드는  6\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "55 회 최적정책 리워드는  6\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "56 회 최적정책 리워드는  6\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "57 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "58 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "59 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "60 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "61 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "62 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "63 회 최적정책 리워드는  6\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "64 회 최적정책 리워드는  6\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "65 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "66 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "67 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "68 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "69 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "70 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "71 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "72 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "73 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "74 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "75 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "76 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "77 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "78 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "79 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "80 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "81 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "82 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "83 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "84 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "85 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "86 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "87 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "88 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "89 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "90 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "91 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "92 회 최적정책 리워드는  999\n",
      "[1, 1, 1, 1, 1, 1] 6\n",
      "93 회 최적정책 리워드는  6\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "94 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "95 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "96 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "97 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "98 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "99 회 최적정책 리워드는  999\n",
      "[0, 1, 0, 1, 0, 0] 999\n",
      "100 회 최적정책 리워드는  999\n",
      "790.47 은 평균\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "class LR_world():\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "\n",
    "    def step(self, a):\n",
    "        if a == 0:\n",
    "            if self.x == [0, 1, 0, 1, 0]:\n",
    "                reward = +1000\n",
    "            else:\n",
    "                reward = -1\n",
    "            self.move_left()\n",
    "        else:\n",
    "            reward = +1\n",
    "            self.move_right()\n",
    "\n",
    "        done = self.is_done()\n",
    "        return self.x, reward, done\n",
    "\n",
    "    def move_left(self):\n",
    "        self.x.append(0)\n",
    "\n",
    "    def move_right(self):\n",
    "        self.x.append(1)\n",
    "\n",
    "    def is_done(self):\n",
    "        if len(self.x) == 6:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x = []\n",
    "        return self.x\n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((200,2))       \n",
    "        self.eps = 0.9\n",
    "        self.alpha = 0.01\n",
    "\n",
    "    # def state(self, s):\n",
    "    #     state = 0\n",
    "    #     if len(s) == 0:\n",
    "    #         state = 1\n",
    "    #     else:\n",
    "    #         state += int(\"\".join([str(bit) for bit in s]), 2)\n",
    "    #     return state\n",
    "    \n",
    "    def state(self, s):\n",
    "        state = 0\n",
    "        for bit in s:\n",
    "            state = state * 2 + bit\n",
    "        if len(s) > 0:\n",
    "            state += 2 ** (len(s) + 1)\n",
    "        return state\n",
    "    \n",
    "    def select_action(self, s):\n",
    "        x = self.state(s)\n",
    "        coin = random.random()\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,1)\n",
    "        else:\n",
    "            action_val = self.q_table[x,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "    \n",
    "    def select_bestaction(self, s):\n",
    "        k = self.state(s)\n",
    "        action_val = self.q_table[k,:]\n",
    "        action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def update_table(self, transition):\n",
    "        s, a, r, s_prime = transition\n",
    "        x = self.state(s)\n",
    "        next_x = self.state(s_prime)\n",
    "        a_prime = self.select_action(s_prime)\n",
    "        self.q_table[x, a] = self.q_table[x, a] + self.alpha * (r + self.q_table[next_x, a_prime] - self.q_table[x, a])\n",
    "        return r\n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.001\n",
    "        self.eps = max(self.eps, 0.2)\n",
    "\n",
    "    def show_table(self):\n",
    "        q_lst = self.q_table.tolist()\n",
    "        #print(q_lst)\n",
    "\n",
    "def main():\n",
    "    env = LR_world()\n",
    "    agent = QAgent()\n",
    "    best_score = -float('inf')\n",
    "    best_epi = []\n",
    "\n",
    "    for n_epi in range(10000):\n",
    "        done = False\n",
    "        score = 0.0\n",
    "        \n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            s = s[:]\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            agent.update_table((copy.deepcopy(s), a, r, copy.deepcopy(s_prime)) )\n",
    "            s = s_prime\n",
    "            score += r\n",
    "        agent.anneal_eps()\n",
    "\n",
    "    #     if score == 999.0:\n",
    "    #         best_epi.append(n_epi)\n",
    "\n",
    "    #     if n_epi%9==0:\n",
    "    #         print(\"n_episode : {}, score : {:.1f}\".format(n_epi, score))\n",
    "    #         agent.show_table()\n",
    "\n",
    "    #     if score >= best_score:\n",
    "    #         best_table = []\n",
    "    #         best_score = score\n",
    "    #         best_table = agent.q_table.tolist()\n",
    "\n",
    "    # print(\"\\nBest table score : {:.1f}, best_episode 갯수: {}\".format(best_score, len(best_epi)))\n",
    "    # print('Best table :', best_table)\n",
    "\n",
    "    done=False\n",
    "    s=env.reset()\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        a = agent.select_bestaction(s)\n",
    "        s_prime, r, done = env.step(a)\n",
    "        total_reward = total_reward + r\n",
    "        s = s_prime\n",
    "    print(s,total_reward)\n",
    "    return total_reward\n",
    "\n",
    "average = 0\n",
    "for i in range(100):\n",
    "    total_reward = main()\n",
    "    print(i+1 , \"회 최적정책 리워드는 \", total_reward)\n",
    "    average = total_reward + average\n",
    "\n",
    "print(average/100, \"은 평균\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
