{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action은 왼쪽으로 이동 (a=0), 오른쪽으로 이동(a=1)\n",
    "# Action 6번하면 Episode 종료\n",
    "# Action을 (0, 1, 0, 1, 0, 0) 순서로 취했을 때 R = +1000\n",
    "# Reward는 오른쪽은 +1, 왼쪽은 -1\n",
    "# (1, 1, 1, 1, 1, 1)은 local optimal : 나오면 안되는 경우\n",
    "\n",
    "####################################\n",
    "#      #      #      #      #      #\n",
    "#      #      # 시작 #      #      #\n",
    "#      #      #      #      #      #\n",
    "####################################\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "class LR_world():\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "\n",
    "    def step(self, a):\n",
    "        if a == 0:\n",
    "            if self.x == [0, 1, 0, 1, 0]:\n",
    "                reward = +1000\n",
    "            else:\n",
    "                reward = -1\n",
    "            self.move_left()\n",
    "            \n",
    "        else:\n",
    "            if self.x == [1, 1, 1, 1, 1]:\n",
    "                reward = -1000\n",
    "            else:\n",
    "                reward = +1\n",
    "            self.move_right()\n",
    "\n",
    "        done = self.is_done()\n",
    "        return self.x, reward, done\n",
    "\n",
    "    def move_left(self):\n",
    "        self.x.append(0)\n",
    "\n",
    "    def move_right(self):\n",
    "        self.x.append(1)\n",
    "\n",
    "    def is_done(self):\n",
    "        if len(self.x) == 6:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x = []\n",
    "        return self.x\n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((127,2))       \n",
    "        self.eps = 0.9\n",
    "        self.alpha = 0.01\n",
    "\n",
    "    def state(self, s):\n",
    "        state = 0\n",
    "        if len(s) == 0:\n",
    "            state = 0\n",
    "        else:\n",
    "            state += int(\"\".join([str(bit) for bit in s]), 2)\n",
    "        return state\n",
    "\n",
    "    def select_action(self, s):\n",
    "        x = self.state(s)\n",
    "        coin = random.random()\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,1)\n",
    "        else:\n",
    "            action_val = self.q_table[x,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def best_action(self, s):\n",
    "        x = self.state(s)\n",
    "        action_val = self.q_table[x, :]\n",
    "        action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def update_table(self, history):\n",
    "        cum_reward = 0\n",
    "        for transition in history[::-1]:\n",
    "            s, a, r, s_prime = transition\n",
    "            x = self.state(s)\n",
    "            cum_reward = cum_reward + r\n",
    "            self.q_table[x, a] = self.q_table[x, a] + self.alpha * (cum_reward - self.q_table[x, a])\n",
    "        return cum_reward\n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.01\n",
    "        self.eps = max(self.eps, 0.1)\n",
    "\n",
    "    def show_table(self):\n",
    "        q_lst = self.q_table.tolist()\n",
    "        print(q_lst)\n",
    "        \n",
    "def main():\n",
    "    env = LR_world()\n",
    "    agent = QAgent()\n",
    "    best_score = -float('inf')\n",
    "    best_table = []\n",
    "    best_epi = []\n",
    "\n",
    "    for n_epi in range(1000):\n",
    "        done = False\n",
    "        history = []\n",
    "        score = 0.0\n",
    "        \n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            s = s[:]\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            history.append((copy.deepcopy(s), a, r, copy.deepcopy(s_prime)))\n",
    "            s = s_prime\n",
    "            score += r\n",
    "\n",
    "        agent.update_table(history) \n",
    "        agent.anneal_eps()\n",
    "\n",
    "        if score == 999.0:\n",
    "            best_epi.append(n_epi)\n",
    "\n",
    "        if n_epi%10==0 or n_epi<10:\n",
    "            print(\"n_episode : {}, score : {:.1f}\".format(n_epi, score))\n",
    "            agent.show_table()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_table = agent.q_table.tolist()\n",
    "\n",
    "    print(\"\\nBest table score : {:.1f}, best_episode 갯수: {}\".format(best_score, len(best_epi)))\n",
    "    print('Best table :', best_table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "class LR_world():\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "\n",
    "    def step(self, a):\n",
    "        if a == 0:\n",
    "            if self.x == [0, 1, 0, 1, 0]:\n",
    "                reward = +1000\n",
    "            else:\n",
    "                reward = -1\n",
    "            self.move_left()\n",
    "            \n",
    "        else:\n",
    "            if self.x == [1, 1, 1, 1, 1]:\n",
    "                reward = -1000\n",
    "            else:\n",
    "                reward = +1\n",
    "            self.move_right()\n",
    "\n",
    "        done = self.is_done()\n",
    "        return self.x, reward, done\n",
    "\n",
    "    def move_left(self):\n",
    "        self.x.append(0)\n",
    "\n",
    "    def move_right(self):\n",
    "        self.x.append(1)\n",
    "\n",
    "    def is_done(self):\n",
    "        if len(self.x) == 6:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x = []\n",
    "        return self.x\n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((127,2))       \n",
    "        self.eps = 0.9\n",
    "        self.alpha = 0.01\n",
    "\n",
    "    def state(self, s):\n",
    "        state = 0\n",
    "        if len(s) == 0:\n",
    "            state = 0\n",
    "        else:\n",
    "            state += int(\"\".join([str(bit) for bit in s]), 2)\n",
    "        return state\n",
    "\n",
    "    def select_action(self, s):\n",
    "        x = self.state(s)\n",
    "        coin = random.random()\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,1)\n",
    "        else:\n",
    "            action_val = self.q_table[x,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def update_table(self, transition):\n",
    "        s, a, r, s_prime = transition\n",
    "        x = self.state(s)\n",
    "        next_x = self.state(s_prime)\n",
    "        a_prime = self.select_action(s_prime)\n",
    "        self.q_table[x, a] = self.q_table[x, a] + self.alpha * (r + self.q_table[next_x, a_prime] - self.q_table[x, a])\n",
    "        return r\n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.01\n",
    "        self.eps = max(self.eps, 0.1)\n",
    "\n",
    "    def show_table(self):\n",
    "        q_lst = self.q_table.tolist()\n",
    "        #print(q_lst)\n",
    "\n",
    "def main():\n",
    "    env = LR_world()\n",
    "    agent = QAgent()\n",
    "    best_score = -float('inf')\n",
    "    best_table = []\n",
    "    best_epi = []\n",
    "\n",
    "    for n_epi in range(10000):\n",
    "        done = False\n",
    "        score = 0.0\n",
    "        \n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            s = s[:]\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            agent.update_table((copy.deepcopy(s), a, r, copy.deepcopy(s_prime)) )\n",
    "            s = s_prime\n",
    "            score += r\n",
    "        agent.anneal_eps()\n",
    "\n",
    "        if score == 999.0:\n",
    "            best_epi.append(n_epi)\n",
    "\n",
    "        if n_epi%10==0 or n_epi<10:\n",
    "            #print(\"n_episode : {}, score : {:.1f}\".format(n_epi, score))\n",
    "            agent.show_table()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_table = agent.q_table.tolist()\n",
    "\n",
    "    print(\"\\nBest table score : {:.1f}, best_episode 갯수: {}\".format(best_score, len(best_epi)))\n",
    "    print('Best table :', best_table)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
